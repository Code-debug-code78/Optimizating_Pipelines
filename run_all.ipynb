{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458a2c9-e65e-4503-98da-489702587cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting all benchmarks ---\n",
      "\n",
      "--- Starting benchmark for Dataset: dblp_scholar, Model Category: maximum_quality ---\n",
      "Loading data from: ./data/dblp_scholar\n",
      "Data loaded: 3207 queries, 3207 references, 64263 candidates.\n",
      "\n",
      "üîç Evaluating baseline fuzzy matcher (RapidFuzz)...\n",
      "--- DEBUG: rapidfuzz (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "RapidFuzz evaluation completed.\n",
      "\n",
      "üöÄ Evaluating embedding models...\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Salesforce/SFR-Embedding-2_R\n",
      "--- DEBUG: Salesforce/SFR-Embedding-2_R (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Salesforce/SFR-Embedding-2_R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: Salesforce/SFR-Embedding-2_R\n",
      "Evaluation for Salesforce/SFR-Embedding-2_R completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Salesforce/SFR-Embedding-Mistral\n",
      "--- DEBUG: Salesforce/SFR-Embedding-Mistral (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Salesforce/SFR-Embedding-Mistral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: Salesforce/SFR-Embedding-Mistral\n",
      "Evaluation for Salesforce/SFR-Embedding-Mistral completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Alibaba-NLP/gte-Qwen2-7B-instruct\n",
      "--- DEBUG: Alibaba-NLP/gte-Qwen2-7B-instruct (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Alibaba-NLP/gte-Qwen2-7B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:05<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: Alibaba-NLP/gte-Qwen2-7B-instruct\n",
      "Evaluation for Alibaba-NLP/gte-Qwen2-7B-instruct completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Qwen/Qwen2-7B-Instruct\n",
      "--- DEBUG: Qwen/Qwen2-7B-Instruct (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Qwen/Qwen2-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: Qwen/Qwen2-7B-Instruct\n",
      "Evaluation for Qwen/Qwen2-7B-Instruct completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: intfloat/e5-mistral-7b-instruct\n",
      "--- DEBUG: intfloat/e5-mistral-7b-instruct (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: intfloat/e5-mistral-7b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: intfloat/e5-mistral-7b-instruct\n",
      "Evaluation for intfloat/e5-mistral-7b-instruct completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: microsoft/Phi-4-mini-instruct\n",
      "--- DEBUG: microsoft/Phi-4-mini-instruct (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: microsoft/Phi-4-mini-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No sentence-transformers model found with name microsoft/Phi-4-mini-instruct. Creating a new one with mean pooling.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded SentenceTransformer model: microsoft/Phi-4-mini-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:49<00:00,  2.04it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2009/2009 [17:16<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for microsoft/Phi-4-mini-instruct completed.\n",
      "\n",
      "üìÑ All predictions saved to: ./results/dblp_scholar_maximum_quality_alethia_results.csv\n",
      "üìä All metrics saved to: ./results/dblp_scholar_maximum_quality_alethia_accuracy.csv\n",
      "\n",
      "‚úÖ Benchmark completed for dblp_scholar and maximum_quality.\n",
      "--- Benchmark for dblp_scholar finished ---\n",
      "\n",
      "--- Starting benchmark for Dataset: dblp_scholar, Model Category: research_experimental ---\n",
      "Loading data from: ./data/dblp_scholar\n",
      "Data loaded: 3207 queries, 3207 references, 64263 candidates.\n",
      "\n",
      "üîç Evaluating baseline fuzzy matcher (RapidFuzz)...\n",
      "--- DEBUG: rapidfuzz (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "RapidFuzz evaluation completed.\n",
      "\n",
      "üöÄ Evaluating embedding models...\n",
      "\n",
      "‚öôÔ∏è Evaluating model: GritLM/GritLM-7B\n",
      "--- DEBUG: GritLM/GritLM-7B (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: GritLM/GritLM-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: GritLM/GritLM-7B\n",
      "Evaluation for GritLM/GritLM-7B completed.\n",
      "\n",
      "üìÑ All predictions saved to: ./results/dblp_scholar_research_experimental_alethia_results.csv\n",
      "üìä All metrics saved to: ./results/dblp_scholar_research_experimental_alethia_accuracy.csv\n",
      "\n",
      "‚úÖ Benchmark completed for dblp_scholar and research_experimental.\n",
      "--- Benchmark for dblp_scholar finished ---\n",
      "\n",
      "--- Starting benchmark for Dataset: dblp_scholar, Model Category: production_balanced ---\n",
      "Loading data from: ./data/dblp_scholar\n",
      "Data loaded: 3207 queries, 3207 references, 64263 candidates.\n",
      "\n",
      "üîç Evaluating baseline fuzzy matcher (RapidFuzz)...\n",
      "--- DEBUG: rapidfuzz (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "RapidFuzz evaluation completed.\n",
      "\n",
      "üöÄ Evaluating embedding models...\n",
      "\n",
      "‚öôÔ∏è Evaluating model: mixedbread-ai/mxbai-embed-large-v1\n",
      "--- DEBUG: mixedbread-ai/mxbai-embed-large-v1 (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: mixedbread-ai/mxbai-embed-large-v1\n",
      "Successfully loaded SentenceTransformer model: mixedbread-ai/mxbai-embed-large-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:05<00:00, 17.62it/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2009/2009 [02:01<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for mixedbread-ai/mxbai-embed-large-v1 completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "--- DEBUG: Alibaba-NLP/gte-Qwen2-1.5B-instruct (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LLM: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "Evaluation for Alibaba-NLP/gte-Qwen2-1.5B-instruct completed.\n",
      "\n",
      "‚öôÔ∏è Evaluating model: Linq-AI-Research/Linq-Embed-Mistral\n",
      "--- DEBUG: Linq-AI-Research/Linq-Embed-Mistral (Data Alignment) ---\n",
      "Total references: 3207, References found in candidate_pool: 3207\n",
      "DEBUG: Attempting to load model: Linq-AI-Research/Linq-Embed-Mistral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded SentenceTransformer model: Linq-AI-Research/Linq-Embed-Mistral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                      | 65/101 [01:30<00:41,  1.14s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# If benchmark_runner.py, scoring.py, and plot_results.py are in the\n",
    "# SAME FOLDER as this notebook, no special sys.path modification is needed.\n",
    "# Python will find them automatically.\n",
    "# If they were in a 'scripts' subdirectory, the previous sys.path code would be correct.\n",
    "\n",
    "from benchmark_runner import run_benchmark_on_dataset\n",
    "from plot_results import plot_benchmark_results\n",
    "\n",
    "datasets = [\n",
    "    \"./data/dblp_scholar\",\n",
    "    # Add more dataset directories here if you have them, e.g.,\n",
    "    # \"./data/abt_buy\",\n",
    "]\n",
    "\n",
    "model_categories = [\n",
    "    \n",
    "    #\"speed_critical\",\n",
    "    \"maximum_quality\",\n",
    "    \"research_experimental\",\n",
    "    \"production_balanced\",\n",
    "    \"memory_constrained\",\n",
    "    \"instruction_following\",\n",
    "    \"fast_embedding\",\n",
    "    \n",
    "    # \"large_models\", # Uncomment if you want to run large models\n",
    "]\n",
    "\n",
    "# --- Run Benchmarks ---\n",
    "print(\"--- Starting all benchmarks ---\")\n",
    "for dataset_path in datasets:\n",
    "    for category in model_categories:\n",
    "        run_benchmark_on_dataset(dataset_path, category)\n",
    "print(\"--- All benchmarks completed ---\")\n",
    "\n",
    "# --- Generate Plots ---\n",
    "print(\"\\n--- Starting plot generation ---\")\n",
    "for dataset_path in datasets:\n",
    "    dataset_base_name = os.path.basename(dataset_path)\n",
    "    for category in model_categories:\n",
    "        metrics_file_path = f\"./results/{dataset_base_name}_{category}_alethia_accuracy.csv\"\n",
    "        # The predictions_file_path is kept for the function signature, even if not directly used for plotting\n",
    "        predictions_file_path = f\"./results/{dataset_base_name}_{category}_alethia_results.csv\"\n",
    "        plots_output_directory = f\"./plots/{dataset_base_name}_{category}_alethia_benchmark_plots\"\n",
    "        pdf_report_filename = f\"{dataset_base_name}_{category}_alethia_benchmark_report.pdf\"\n",
    "\n",
    "        # Check if the metrics file exists before attempting to plot\n",
    "        if os.path.exists(metrics_file_path):\n",
    "            plot_benchmark_results(metrics_file_path, predictions_file_path, plots_output_directory, pdf_report_filename)\n",
    "        else:\n",
    "            print(f\"Skipping plotting for {metrics_file_path}: Metrics file not found. Benchmark might have skipped for this combination.\")\n",
    "print(\"--- All plots generated ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095fd2ed-0f22-4ea8-94dd-326a10a18ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/mahimasahu/miniconda3/envs/alethia2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting plot generation ---\n",
      "Loading metrics from: ./results/dblp_scholar_maximum_quality_alethia_accuracy.csv\n",
      "Loading predictions from: ./results/dblp_scholar_maximum_quality_alethia_results.csv\n",
      "Added Top-1 Accuracy plot to PDF.\n",
      "Added Mean Reciprocal Rank (MRR) plot to PDF.\n",
      "Added Average Inference Time plot to PDF.\n",
      "Added Memory Usage plot to PDF.\n",
      "Added Accuracy vs. Inference Time plot to PDF.\n",
      "Skipped Match Score Distribution plot as requested.\n",
      "Added Correct vs Incorrect Predictions plot to PDF.\n",
      "\n",
      "All requested plots generated and saved to './plots/dblp_scholar_maximum_quality_alethia_benchmark_plots/dblp_scholar_maximum_quality_alethia_benchmark_report.pdf'.\n",
      "Loading metrics from: ./results/dblp_scholar_research_experimental_alethia_accuracy.csv\n",
      "Loading predictions from: ./results/dblp_scholar_research_experimental_alethia_results.csv\n",
      "Added Top-1 Accuracy plot to PDF.\n",
      "Added Mean Reciprocal Rank (MRR) plot to PDF.\n",
      "Added Average Inference Time plot to PDF.\n",
      "Added Memory Usage plot to PDF.\n",
      "Added Accuracy vs. Inference Time plot to PDF.\n",
      "Skipped Match Score Distribution plot as requested.\n",
      "Added Correct vs Incorrect Predictions plot to PDF.\n",
      "\n",
      "All requested plots generated and saved to './plots/dblp_scholar_research_experimental_alethia_benchmark_plots/dblp_scholar_research_experimental_alethia_benchmark_report.pdf'.\n",
      "--- All plots generated ---\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Plots ---\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# If benchmark_runner.py, scoring.py, and plot_results.py are in the\n",
    "# SAME FOLDER as this notebook, no special sys.path modification is needed.\n",
    "# Python will find them automatically.\n",
    "# If they were in a 'scripts' subdirectory, the previous sys.path code would be correct.\n",
    "\n",
    "from benchmark_runner import run_benchmark_on_dataset\n",
    "from plot_results import plot_benchmark_results\n",
    "\n",
    "datasets = [\n",
    "    \"./data/dblp_scholar\",\n",
    "    # Add more dataset directories here if you have them, e.g.,\n",
    "    # \"./data/abt_buy\",\n",
    "]\n",
    "\n",
    "model_categories = [\n",
    "    \n",
    "    #\"speed_critical\",\n",
    "    \"maximum_quality\",\n",
    "    \"research_experimental\",\n",
    "    \n",
    "    \n",
    "    # \"large_models\", # Uncomment if you want to run large models\n",
    "]\n",
    "\n",
    "print(\"\\n--- Starting plot generation ---\")\n",
    "for dataset_path in datasets:\n",
    "    dataset_base_name = os.path.basename(dataset_path)\n",
    "    for category in model_categories:\n",
    "        metrics_file_path = f\"./results/{dataset_base_name}_{category}_alethia_accuracy.csv\"\n",
    "        # The predictions_file_path is kept for the function signature, even if not directly used for plotting\n",
    "        predictions_file_path = f\"./results/{dataset_base_name}_{category}_alethia_results.csv\"\n",
    "        plots_output_directory = f\"./plots/{dataset_base_name}_{category}_alethia_benchmark_plots\"\n",
    "        pdf_report_filename = f\"{dataset_base_name}_{category}_alethia_benchmark_report.pdf\"\n",
    "\n",
    "        # Check if the metrics file exists before attempting to plot\n",
    "        if os.path.exists(metrics_file_path):\n",
    "            plot_benchmark_results(metrics_file_path, predictions_file_path, plots_output_directory, pdf_report_filename)\n",
    "        else:\n",
    "            print(f\"Skipping plotting for {metrics_file_path}: Metrics file not found. Benchmark might have skipped for this combination.\")\n",
    "print(\"--- All plots generated ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5216dc2-820d-485b-b6bb-b8f65b852d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
